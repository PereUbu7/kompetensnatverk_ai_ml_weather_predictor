{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                 date  airTemp  airPressure  relAirHumidity  \\\n",
      "0           0  2018-11-10 01:00:00      5.6       1017.3              98   \n",
      "1           1  2018-11-10 02:00:00      5.6       1017.0              98   \n",
      "2           2  2018-11-10 03:00:00      5.8       1016.4              98   \n",
      "\n",
      "   sightDistance  weather  windSpeed  windDirection  weather_100     ...       \\\n",
      "0           3400      161          2            100            0     ...        \n",
      "1           1000      123          1             90            0     ...        \n",
      "2            300      134          2             90            0     ...        \n",
      "\n",
      "   weather_171  weather_172  weather_173  weather_177  weather_178  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "\n",
      "   weather_180  weather_181  weather_182  weather_185  weather_509  \n",
      "0            0            0            0            0            0  \n",
      "1            0            0            0            0            0  \n",
      "2            0            0            0            0            0  \n",
      "\n",
      "[3 rows x 38 columns]\n",
      "(1953, 38)\n",
      "(1953, 6)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Read csv data into pandas dataframe\n",
    "df = pd.read_csv(\"weatherData/weatherTable.csv\")\n",
    "\n",
    "# Convert dataframe into numpy array\n",
    "data = np.array(df.values)\n",
    "\n",
    "# Extract real columns\n",
    "realData = data[:, [2, 3, 4, 5, 7, 8]]\n",
    "\n",
    "print(df.head(3))\n",
    "print(data.shape)\n",
    "print(realData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "numberOfColumns = realData.shape[1]\n",
    "learningRate = 0.01\n",
    "numberOfEpochs = 50000\n",
    "\n",
    "# How much data should be used for training\n",
    "trainingSetRatio = 0.8\n",
    "\n",
    "# How many samples in sequence\n",
    "sampleSequence = 5\n",
    "\n",
    "# How many samples away from end of sample sequence should we predict. 0 is next prediction of next sample\n",
    "predictionTime = 0\n",
    "\n",
    "print(numberOfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 30)\n",
      "(0, 30)\n",
      "(0, 6)\n",
      "(0, 6)\n"
     ]
    }
   ],
   "source": [
    "trainingData = np.empty(shape=(0, sampleSequence*numberOfColumns))\n",
    "validationData = np.empty(shape=(0, sampleSequence*numberOfColumns))\n",
    "trainingTarget = np.empty(shape=(0, numberOfColumns))\n",
    "validationTarget= np.empty(shape=(0, numberOfColumns))\n",
    "\n",
    "print(trainingData.shape)\n",
    "print(validationData.shape)\n",
    "print(trainingTarget.shape)\n",
    "print(validationTarget.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[311, 210, 911, 16, 679, 1236, 38, 970, 529, 118]\n"
     ]
    }
   ],
   "source": [
    "# Create a randomly shuffled selection of data\n",
    "availableShuffledIndices = [*range(realData.shape[0] - sampleSequence - predictionTime)]\n",
    "\n",
    "print(availableShuffledIndices[0:10])\n",
    "\n",
    "shuffle(availableShuffledIndices)\n",
    "\n",
    "print(availableShuffledIndices[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1559, 30)\n",
      "(389, 30)\n",
      "(1559, 6)\n",
      "(389, 6)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and validation data sets\n",
    "for i in range(len(availableShuffledIndices)):\n",
    "\n",
    "    currentIndex = availableShuffledIndices[i]\n",
    "\n",
    "    # Extract sample\n",
    "    s = [x + currentIndex for x in range(sampleSequence)]\n",
    "    st = currentIndex + sampleSequence + predictionTime\n",
    "    sample = np.expand_dims(np.reshape(realData[s, :], (sampleSequence*numberOfColumns)), 0)\n",
    "    sampleTarget = np.expand_dims(realData[st, :], 0)\n",
    "\n",
    "    # Create training data set\n",
    "    if i < len(availableShuffledIndices) * trainingSetRatio:\n",
    "        trainingData = np.append(trainingData, sample, 0)\n",
    "        trainingTarget = np.append(trainingTarget, sampleTarget, 0)\n",
    "\n",
    "    # Create validation data set\n",
    "    else:\n",
    "        validationData = np.append(validationData, sample, 0)\n",
    "        validationTarget = np.append(validationTarget, sampleTarget, 0)\n",
    "\n",
    "print(trainingData.shape)\n",
    "print(validationData.shape)\n",
    "print(trainingTarget.shape)\n",
    "print(validationTarget.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cd4190dcdbcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\martin.noring\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\martin.noring\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    492\u001b[0m                        \u001b[1;34m\"Optimizer.GATE_OP, Optimizer.GATE_GRAPH.  Not %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                        gate_gradients)\n\u001b[1;32m--> 494\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_valid_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgrad_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_valid_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\martin.noring\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36m_assert_valid_dtypes\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[0mvalid_dtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_valid_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_dtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         raise ValueError(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "# Create your artificial neural network here\n",
    "\n",
    "# ...\n",
    "\n",
    "loss = ...\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learningRate)\n",
    "\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is for plotting purposes\n",
    "trainingLossLog = []\n",
    "validationLossLog = []\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b9560e391802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumberOfEpochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# Your training loop here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(numberOfEpochs):\n",
    "        # Your training loop here\n",
    "        \n",
    "        _, trainingLoss = ...\n",
    "        \n",
    "        pred, validationLoss = ...\n",
    "        \n",
    "        print(\"\\rPrediction: {} Target {} Training loss: {:.2f} Validation loss: {:.2f}\".format(pred[0,:], validationData[0,-(numberOfColumns):], trainingLoss, validationLoss), end=\"\")\n",
    "        \n",
    "        trainingLossLog.append(np.log(trainingLoss))\n",
    "        validationLossLog.append(np.log(validationLoss))\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            plt.plot(trainingLossLog, 'r')\n",
    "            plt.plot(validationLossLog, 'b')\n",
    "            plt.xlabel(\"Episode\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Training and validiation log loss\")\n",
    "            plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
